{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fa61ab",
   "metadata": {},
   "source": [
    "# Data Preprocessing - Housing Price Prediction\n",
    "\n",
    "This notebook demonstrates data cleaning and transformation for the Kaggle House Prices dataset as part of the Housing Price Prediction Project. It includes:\n",
    "- Loading the raw dataset (`/Users/junshao/bootcamp_Jun_Shao/project/data/raw/train.csv`).\n",
    "- Applying cleaning functions from `src/cleaning.py` (fill missing, drop duplicates, normalize, encode categorical).\n",
    "- Saving the preprocessed dataset to `/data/processed/preprocessed_train.csv`.\n",
    "- Documenting assumptions made during cleaning.\n",
    "\n",
    "The goal is to prepare the dataset for modeling, handling missing values, duplicates, scaling, and encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f817a85",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Explanation**:\n",
    "- Import libraries: `pandas` for data handling, `os` and `dotenv` for environment variables.\n",
    "- Add project root to `sys.path` to import `src.cleaning`.\n",
    "- Load environment variables for paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afc7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR_RAW: data/raw\n",
      "DATA_DIR_PROCESSED: data/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.cleaning import fill_missing, drop_duplicates, normalize_data, encode_categorical\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DATA_DIR_RAW = os.getenv('DATA_DIR_RAW')\n",
    "DATA_DIR_PROCESSED = os.getenv('DATA_DIR_PROCESSED')\n",
    "\n",
    "# Verify environment variables\n",
    "print(f'DATA_DIR_RAW: {DATA_DIR_RAW}')\n",
    "print(f'DATA_DIR_PROCESSED: {DATA_DIR_PROCESSED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a82b4f",
   "metadata": {},
   "source": [
    "## Load Raw Data\n",
    "\n",
    "**Explanation**:\n",
    "- Load the Kaggle train dataset using absolute path.\n",
    "- Display shape, preview, and missing values to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (1460, 81)\n",
      "Original Data Preview:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "Missing Values Before Cleaning:\n",
      "LotFrontage     259\n",
      "Alley          1369\n",
      "PoolQC         1453\n",
      "Fence          1179\n",
      "MiscFeature    1406\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load raw dataset\n",
    "raw_file = '/Users/junshao/bootcamp_Jun_Shao/project/data/raw/train.csv'\n",
    "df = pd.read_csv(raw_file)\n",
    "\n",
    "# Display initial state\n",
    "print('Original Data Shape:', df.shape)\n",
    "print('Original Data Preview:')\n",
    "print(df.head())\n",
    "print('\\nMissing Values Before Cleaning:')\n",
    "print(df[['LotFrontage', 'Alley', 'PoolQC', 'Fence', 'MiscFeature']].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228dff23",
   "metadata": {},
   "source": [
    "## Apply Preprocessing Functions\n",
    "\n",
    "**Explanation**:\n",
    "- Fill missing values (median for numeric, 'None' for categorical).\n",
    "- Drop duplicates.\n",
    "- Normalize numeric columns.\n",
    "- Encode categorical columns.\n",
    "- Display state after each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e1ce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Filling:\n",
      "LotFrontage    0\n",
      "Alley          0\n",
      "PoolQC         0\n",
      "Fence          0\n",
      "MiscFeature    0\n",
      "dtype: int64\n",
      "\n",
      "Data Shape After Dropping Duplicates: (1460, 81)\n",
      "\n",
      "Data After Normalization (Preview):\n",
      "   SalePrice   LotArea  GrLivArea  OverallQual\n",
      "0   0.241078  0.033420   0.259231     0.666667\n",
      "1   0.203583  0.038795   0.174830     0.555556\n",
      "2   0.261908  0.046507   0.273549     0.666667\n",
      "3   0.145952  0.038561   0.260550     0.666667\n",
      "4   0.298709  0.060576   0.351168     0.777778\n",
      "\n",
      "Data After Encoding (Shape): (1460, 123)\n",
      "Data After Encoding (Preview):\n",
      "   Id  LotFrontage   LotArea Street Alley LotShape LandContour Utilities  \\\n",
      "0   1         65.0  0.033420   Pave  None      Reg         Lvl    AllPub   \n",
      "1   2         80.0  0.038795   Pave  None      Reg         Lvl    AllPub   \n",
      "2   3         68.0  0.046507   Pave  None      IR1         Lvl    AllPub   \n",
      "3   4         60.0  0.038561   Pave  None      IR1         Lvl    AllPub   \n",
      "4   5         84.0  0.060576   Pave  None      IR1         Lvl    AllPub   \n",
      "\n",
      "  LotConfig LandSlope  ... Neighborhood_NoRidge Neighborhood_NridgHt  \\\n",
      "0    Inside       Gtl  ...                  0.0                  0.0   \n",
      "1       FR2       Gtl  ...                  0.0                  0.0   \n",
      "2    Inside       Gtl  ...                  0.0                  0.0   \n",
      "3    Corner       Gtl  ...                  0.0                  0.0   \n",
      "4       FR2       Gtl  ...                  1.0                  0.0   \n",
      "\n",
      "  Neighborhood_OldTown Neighborhood_SWISU  Neighborhood_Sawyer  \\\n",
      "0                  0.0                0.0                  0.0   \n",
      "1                  0.0                0.0                  0.0   \n",
      "2                  0.0                0.0                  0.0   \n",
      "3                  0.0                0.0                  0.0   \n",
      "4                  0.0                0.0                  0.0   \n",
      "\n",
      "   Neighborhood_SawyerW  Neighborhood_Somerst  Neighborhood_StoneBr  \\\n",
      "0                   0.0                   0.0                   0.0   \n",
      "1                   0.0                   0.0                   0.0   \n",
      "2                   0.0                   0.0                   0.0   \n",
      "3                   0.0                   0.0                   0.0   \n",
      "4                   0.0                   0.0                   0.0   \n",
      "\n",
      "  Neighborhood_Timber Neighborhood_Veenker  \n",
      "0                 0.0                  0.0  \n",
      "1                 0.0                  1.0  \n",
      "2                 0.0                  0.0  \n",
      "3                 0.0                  0.0  \n",
      "4                 0.0                  0.0  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "df_clean = fill_missing(df)\n",
    "print('Missing Values After Filling:')\n",
    "print(df_clean[['LotFrontage', 'Alley', 'PoolQC', 'Fence', 'MiscFeature']].isna().sum())\n",
    "\n",
    "# Drop duplicates\n",
    "df_clean = drop_duplicates(df_clean)\n",
    "print('\\nData Shape After Dropping Duplicates:', df_clean.shape)\n",
    "\n",
    "# Normalize numeric columns\n",
    "numeric_cols = ['SalePrice', 'LotArea', 'GrLivArea', 'OverallQual']\n",
    "df_clean = normalize_data(df_clean, numeric_cols)\n",
    "print('\\nData After Normalization (Preview):')\n",
    "print(df_clean[numeric_cols].head())\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = ['MSSubClass', 'MSZoning', 'Neighborhood']\n",
    "df_preprocessed = encode_categorical(df_clean, categorical_cols)\n",
    "print('\\nData After Encoding (Shape):', df_preprocessed.shape)\n",
    "print('Data After Encoding (Preview):')\n",
    "print(df_preprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e13b01",
   "metadata": {},
   "source": [
    "## Save Preprocessed Dataset\n",
    "\n",
    "**Explanation**:\n",
    "- Save the preprocessed DataFrame to `/data/processed/preprocessed_train.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c0c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data to /Users/junshao/bootcamp_Jun_Shao/project/data/processed/preprocessed_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "preprocessed_file = '/Users/junshao/bootcamp_Jun_Shao/project/data/processed/preprocessed_train.csv'\n",
    "df_preprocessed.to_csv(preprocessed_file, index=False)\n",
    "print(f'Saved preprocessed data to {preprocessed_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d84af",
   "metadata": {},
   "source": [
    "## Assumptions and Rationale\n",
    "\n",
    "**Assumptions**:\n",
    "- Missing numeric values (e.g., LotFrontage) are random and suitable for median imputation due to skewness.\n",
    "- Missing categorical values represent 'None' (e.g., no basement for BsmtQual), as per data_description.txt.\n",
    "- Duplicates are errors and can be removed without significant loss.\n",
    "- Normalization (Min-Max) is appropriate for numeric features to improve model performance, assuming no extreme outliers post-cleaning.\n",
    "- One-hot encoding is suitable for categorical features, assuming they are nominal and dimensionality increase is manageable.\n",
    "\n",
    "**Rationale**:\n",
    "- Median imputation handles skewness in numeric features (e.g., LotArea).\n",
    "- 'None' filling for categorical aligns with dataset semantics, avoiding bias.\n",
    "- Normalization scales features to [0, 1] for better model convergence.\n",
    "- Encoding transforms categorical data for machine learning, though it increases columns.\n",
    "\n",
    "**Tradeoffs**:\n",
    "- Imputation vs. deletion: Imputation retains data but may introduce bias; deletion reduces bias but loses information.\n",
    "- One-hot vs. label encoding: One-hot avoids ordinal assumptions but increases dimensionality.\n",
    "- Normalization vs. standardization: Min-Max is simple but sensitive to outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
