{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67e92df",
   "metadata": {},
   "source": [
    "# Python Fundamentals Summary - Housing Price Prediction\n",
    "\n",
    "This notebook demonstrates Python, NumPy, and pandas operations using the Kaggle House Prices train dataset as part of the Housing Price Prediction Project. It includes:\n",
    "- Loading and inspecting the dataset (`../data/raw/train.csv`).\n",
    "- Performing NumPy operations (e.g., vectorized calculations on SalePrice).\n",
    "- Performing pandas operations (e.g., summary statistics, grouping by Neighborhood).\n",
    "- Applying reusable utility functions from `src/utils.py` (e.g., clean_column_names, convert_year_to_age).\n",
    "- Saving cleaned data to `/data/processed/train_cleaned.csv`.\n",
    "\n",
    "The goal is to establish foundational Python skills for data preprocessing, exploratory data analysis (EDA), and modeling in later stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76d2e7",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Explanation**:\n",
    "- Import libraries: `pandas` for data handling, `numpy` for numerical operations, `os` and `dotenv` for environment variables.\n",
    "- Add project root to `sys.path` to import `src.utils`.\n",
    "- Load environment variables for paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d66617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR_RAW: data/raw\n",
      "DATA_DIR_PROCESSED: data/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_column_names(df):\n",
    "    \"\"\"\n",
    "    Standardize DataFrame column names by converting to lowercase and replacing spaces/special\n",
    "    characters with underscores.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned column names.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.lower().str.replace(r'[^a-z0-9]', '_', regex=True)\n",
    "    return df\n",
    "\n",
    "def convert_year_to_age(df, year_columns, current_year=2025):\n",
    "    \"\"\"\n",
    "    Convert year columns to age relative to current_year.\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col in year_columns:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column {col} not found in DataFrame\")\n",
    "        age_col = \"house_age\" if col == \"yearbuilt\" else \"remodel_age\"\n",
    "        df[age_col] = current_year - df[col]\n",
    "    return df\n",
    "\n",
    "def save_data(df, filename, data_dir):\n",
    "    \"\"\"\n",
    "    Save DataFrame to CSV in the specified directory, creating folders if needed.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        filename (str): Name of the file (e.g., 'train_cleaned.csv').\n",
    "        data_dir (str): Directory path to save the file.\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the saved file.\n",
    "    \"\"\"\n",
    "    os.makedirs(data_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    return filepath\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DATA_DIR_RAW = os.getenv('DATA_DIR_RAW')\n",
    "DATA_DIR_PROCESSED = os.getenv('DATA_DIR_PROCESSED')\n",
    "\n",
    "# Verify environment variables\n",
    "print(f'DATA_DIR_RAW: {DATA_DIR_RAW}')\n",
    "print(f'DATA_DIR_PROCESSED: {DATA_DIR_PROCESSED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9db2b",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "**Explanation**:\n",
    "- Load the Kaggle train dataset from `../data/raw/train.csv` (relative to notebook in /notebooks/).\n",
    "- Display shape, preview, and missing value counts to confirm structure (includes SalePrice, LotArea, Neighborhood, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40cf408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (1460, 81)\n",
      "Data Preview:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "\n",
      "Missing Values:\n",
      "Id                 0\n",
      "MSSubClass         0\n",
      "MSZoning           0\n",
      "LotFrontage      259\n",
      "LotArea            0\n",
      "                ... \n",
      "MoSold             0\n",
      "YrSold             0\n",
      "SaleType           0\n",
      "SaleCondition      0\n",
      "SalePrice          0\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data_path = os.path.join(DATA_DIR_RAW, 'train.csv')\n",
    "df = pd.read_csv('/Users/junshao/bootcamp_Jun_Shao/project/data/raw/train.csv')\n",
    "\n",
    "# Display initial state\n",
    "print('Data Shape:', df.shape)\n",
    "print('Data Preview:')\n",
    "print(df.head())\n",
    "print('\\nMissing Values:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67edc36b",
   "metadata": {},
   "source": [
    "## NumPy Operations\n",
    "\n",
    "**Explanation**:\n",
    "- Extract the `SalePrice` column as a NumPy array.\n",
    "- Perform element-wise squaring using loop and vectorized methods.\n",
    "- Compare execution times to demonstrate NumPy's efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59dfeef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop time: 0.0002 seconds\n",
      "Vectorized time: 0.0001 seconds\n",
      "First 5 squared values: [43472250000 32942250000 49952250000 19600000000 62500000000]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Extract SalePrice column as a NumPy array\n",
    "prices = df['SalePrice'].to_numpy()\n",
    "\n",
    "# Loop-based squaring\n",
    "start_time = time.time()\n",
    "loop_result = [x**2 for x in prices]\n",
    "loop_time = time.time() - start_time\n",
    "\n",
    "# Vectorized squaring\n",
    "start_time = time.time()\n",
    "vectorized_result = np.square(prices)\n",
    "vectorized_time = time.time() - start_time\n",
    "\n",
    "# Print results\n",
    "print(f'Loop time: {loop_time:.4f} seconds')\n",
    "print(f'Vectorized time: {vectorized_time:.4f} seconds')\n",
    "print(f'First 5 squared values: {vectorized_result[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d9a0a",
   "metadata": {},
   "source": [
    "## Pandas Operations\n",
    "\n",
    "**Explanation**:\n",
    "- Calculate summary statistics for numeric columns (e.g., SalePrice, LotArea, GrLivArea, OverallQual).\n",
    "- Group by `Neighborhood` to compute mean SalePrice, demonstrating aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7fac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "           SalePrice        LotArea    GrLivArea  OverallQual\n",
      "count    1460.000000    1460.000000  1460.000000  1460.000000\n",
      "mean   180921.195890   10516.828082  1515.463699     6.099315\n",
      "std     79442.502883    9981.264932   525.480383     1.382997\n",
      "min     34900.000000    1300.000000   334.000000     1.000000\n",
      "25%    129975.000000    7553.500000  1129.500000     5.000000\n",
      "50%    163000.000000    9478.500000  1464.000000     6.000000\n",
      "75%    214000.000000   11601.500000  1776.750000     7.000000\n",
      "max    755000.000000  215245.000000  5642.000000    10.000000\n",
      "\n",
      "Groupby Neighborhood (Mean SalePrice):\n",
      "Neighborhood\n",
      "Blmngtn    194870.882353\n",
      "Blueste    137500.000000\n",
      "BrDale     104493.750000\n",
      "BrkSide    124834.051724\n",
      "ClearCr    212565.428571\n",
      "CollgCr    197965.773333\n",
      "Crawfor    210624.725490\n",
      "Edwards    128219.700000\n",
      "Gilbert    192854.506329\n",
      "IDOTRR     100123.783784\n",
      "MeadowV     98576.470588\n",
      "Mitchel    156270.122449\n",
      "NAmes      145847.080000\n",
      "NPkVill    142694.444444\n",
      "NWAmes     189050.068493\n",
      "NoRidge    335295.317073\n",
      "NridgHt    316270.623377\n",
      "OldTown    128225.300885\n",
      "SWISU      142591.360000\n",
      "Sawyer     136793.135135\n",
      "SawyerW    186555.796610\n",
      "Somerst    225379.837209\n",
      "StoneBr    310499.000000\n",
      "Timber     242247.447368\n",
      "Veenker    238772.727273\n",
      "Name: SalePrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select key numeric columns for summary\n",
    "numeric_cols = ['SalePrice', 'LotArea', 'GrLivArea', 'OverallQual']\n",
    "print('Summary Statistics:')\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Groupby aggregation\n",
    "print('\\nGroupby Neighborhood (Mean SalePrice):')\n",
    "print(df.groupby('Neighborhood')['SalePrice'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56e398",
   "metadata": {},
   "source": [
    "## Apply Utility Functions\n",
    "\n",
    "**Explanation**:\n",
    "- Apply `clean_column_names` to standardize column names (e.g., YearBuilt -> year_built).\n",
    "- Apply `convert_year_to_age` to create age features from `year_built` and `year_remod_add`.\n",
    "- Demonstrate reusability for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f852650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Column Names:\n",
      "Index(['id', 'mssubclass', 'mszoning', 'lotfrontage', 'lotarea', 'street',\n",
      "       'alley', 'lotshape', 'landcontour', 'utilities', 'lotconfig',\n",
      "       'landslope', 'neighborhood', 'condition1', 'condition2', 'bldgtype',\n",
      "       'housestyle', 'overallqual', 'overallcond', 'yearbuilt', 'yearremodadd',\n",
      "       'roofstyle', 'roofmatl', 'exterior1st', 'exterior2nd', 'masvnrtype',\n",
      "       'masvnrarea', 'exterqual', 'extercond', 'foundation', 'bsmtqual',\n",
      "       'bsmtcond', 'bsmtexposure', 'bsmtfintype1', 'bsmtfinsf1',\n",
      "       'bsmtfintype2', 'bsmtfinsf2', 'bsmtunfsf', 'totalbsmtsf', 'heating',\n",
      "       'heatingqc', 'centralair', 'electrical', '1stflrsf', '2ndflrsf',\n",
      "       'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath', 'fullbath',\n",
      "       'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
      "       'totrmsabvgrd', 'functional', 'fireplaces', 'fireplacequ', 'garagetype',\n",
      "       'garageyrblt', 'garagefinish', 'garagecars', 'garagearea', 'garagequal',\n",
      "       'garagecond', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
      "       'enclosedporch', '3ssnporch', 'screenporch', 'poolarea', 'poolqc',\n",
      "       'fence', 'miscfeature', 'miscval', 'mosold', 'yrsold', 'saletype',\n",
      "       'salecondition', 'saleprice'],\n",
      "      dtype='object')\n",
      "\n",
      "Data Types After Converting Years:\n",
      "yearbuilt       int64\n",
      "yearremodadd    int64\n",
      "house_age       int64\n",
      "remodel_age     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply clean_column_names\n",
    "df_clean = clean_column_names(df)\n",
    "print('Cleaned Column Names:')\n",
    "print(df_clean.columns)\n",
    "\n",
    "# Apply convert_year_to_age\n",
    "df_clean = convert_year_to_age(df_clean, ['yearbuilt', 'yearremodadd'])\n",
    "print('\\nData Types After Converting Years:')\n",
    "print(df_clean[['yearbuilt', 'yearremodadd', 'house_age', 'remodel_age']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645a12e",
   "metadata": {},
   "source": [
    "## Save Cleaned Data\n",
    "\n",
    "**Explanation**:\n",
    "- Save the cleaned DataFrame to `/data/processed/train_cleaned.csv` using `save_data` from `src/utils.py`.\n",
    "- This demonstrates reproducible data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2af2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned data to data/processed/train_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned data\n",
    "saved_path = save_data(df_clean, 'train_cleaned.csv', DATA_DIR_PROCESSED)\n",
    "print(f'Saved cleaned data to {saved_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ff9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
