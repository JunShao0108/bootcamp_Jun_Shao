{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd23bf80",
   "metadata": {},
   "source": [
    "# HW6: Data Cleaning - Housing Price Prediction\n",
    "\n",
    "This notebook implements a modular data cleaning workflow for an Alpha Vantage AAPL stock dataset. It includes:\n",
    "- Loading the raw dataset from `data/raw/api_alphavantage_AAPL_20250820-1804.csv`.\n",
    "- Applying cleaning functions (`fill_missing_median`, `drop_missing`, `normalize_data`) from `src/cleaning.py`.\n",
    "- Saving the cleaned dataset to `data/processed/`.\n",
    "- Comparing original vs. cleaned data.\n",
    "- Documenting assumptions and tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4c560",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "**Explanation**:\n",
    "- Import libraries: `pandas` for data handling, `os` and `dotenv` for environment variables.\n",
    "- Add project root to `sys.path` to import `src.cleaning`.\n",
    "- Load environment variables for paths.\n",
    "- Set timestamp for output filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21daac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR_RAW: data/raw\n",
      "DATA_DIR_PROCESSED: data/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.cleaning import fill_missing_median, drop_missing, normalize_data\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "DATA_DIR_RAW = os.getenv('DATA_DIR_RAW')\n",
    "DATA_DIR_PROCESSED = os.getenv('DATA_DIR_PROCESSED')\n",
    "\n",
    "# Get timestamp for filename\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "\n",
    "# Verify environment variables\n",
    "print(f'DATA_DIR_RAW: {DATA_DIR_RAW}')\n",
    "print(f'DATA_DIR_PROCESSED: {DATA_DIR_PROCESSED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ce2d5",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "**Explanation**:\n",
    "- Load the raw dataset from `data/raw/api_alphavantage_AAPL_20250820-1804.csv`.\n",
    "- Display shape, NA counts, and preview to understand initial data state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c276bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (158, 6)\n",
      "Original NA Counts:\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n",
      "Original Data Preview:\n",
      "         date    open      high       low   close    volume\n",
      "0  2024-08-16  223.92  226.8271  223.6501  226.05  44340240\n",
      "1  2024-08-15  224.60  225.3500  222.7600  224.72  46414013\n",
      "2  2024-08-14  220.57  223.0300  219.7000  221.72  41960574\n",
      "3  2024-08-13  219.01  221.8900  219.0100  221.27  44155331\n",
      "4  2024-08-12  216.07  219.5099  215.6000  217.53  38028092\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 构造绝对路径\n",
    "raw_file = '/Users/junshao/bootcamp_Jun_Shao/homework/hw5/data/raw/api_alphavantage_AAPL_20250820-1804.csv'\n",
    "\n",
    "# 加载数据集\n",
    "df_raw = pd.read_csv(raw_file)\n",
    "\n",
    "# 显示初始状态\n",
    "print('Original Data Shape:', df_raw.shape)\n",
    "print('Original NA Counts:')\n",
    "print(df_raw.isna().sum())\n",
    "print('\\nOriginal Data Preview:')\n",
    "print(df_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b905f6",
   "metadata": {},
   "source": [
    "## Apply Cleaning Functions\n",
    "\n",
    "**Explanation**:\n",
    "- Apply `fill_missing_median` to numeric columns (`open`, `high`, `low`, `close`, `volume`) to handle missing values.\n",
    "- Apply `drop_missing` to remove any remaining rows with NAs.\n",
    "- Apply `normalize_data` to numeric columns for Min-Max scaling.\n",
    "- Save cleaned dataset to `data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f671845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling missing values:\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n",
      "After dropping missing rows:\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n",
      "After normalization:\n",
      "         date      open      high       low     close    volume\n",
      "0  2024-08-16  0.823422  0.853129  0.863220  0.874391  0.045765\n",
      "1  2024-08-15  0.832982  0.832274  0.850322  0.855342  0.055557\n",
      "2  2024-08-14  0.776325  0.799520  0.805984  0.812375  0.034528\n",
      "3  2024-08-13  0.754393  0.783425  0.795986  0.805930  0.044891\n",
      "4  2024-08-12  0.713061  0.749822  0.746577  0.752363  0.015958\n",
      "Saved cleaned data to data/processed/cleaned_alphavantage_AAPL_20250820-1917.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junshao/bootcamp_Jun_Shao/homework/hw6/src/cleaning.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median, inplace=True)\n",
      "/Users/junshao/bootcamp_Jun_Shao/homework/hw6/src/cleaning.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median, inplace=True)\n",
      "/Users/junshao/bootcamp_Jun_Shao/homework/hw6/src/cleaning.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median, inplace=True)\n",
      "/Users/junshao/bootcamp_Jun_Shao/homework/hw6/src/cleaning.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median, inplace=True)\n",
      "/Users/junshao/bootcamp_Jun_Shao/homework/hw6/src/cleaning.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fill missing values in numeric columns with median\n",
    "numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "df_clean = fill_missing_median(df_raw, numeric_columns)\n",
    "print('After filling missing values:')\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "# Step 2: Drop rows with any remaining missing values\n",
    "df_clean = drop_missing(df_clean)\n",
    "print('\\nAfter dropping missing rows:')\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "# Step 3: Normalize numeric columns\n",
    "df_clean = normalize_data(df_clean, numeric_columns)\n",
    "print('\\nAfter normalization:')\n",
    "print(df_clean.head())\n",
    "\n",
    "# Step 4: Save cleaned dataset\n",
    "cleaned_file = os.path.join(DATA_DIR_PROCESSED, f'cleaned_alphavantage_AAPL_{timestamp}.csv')\n",
    "os.makedirs(DATA_DIR_PROCESSED, exist_ok=True)\n",
    "df_clean.to_csv(cleaned_file, index=False)\n",
    "print(f'Saved cleaned data to {cleaned_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c3ddb",
   "metadata": {},
   "source": [
    "## Compare Original vs Cleaned Data\n",
    "\n",
    "**Explanation**:\n",
    "- Compare shapes, NA counts, and statistics of `close` column (representative numeric column).\n",
    "- Reflect on the impact of cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e1c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Shape: (158, 6)\n",
      "Cleaned Data Shape: (158, 6)\n",
      "\n",
      "Original NA Counts:\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "Cleaned NA Counts:\n",
      "date      0\n",
      "open      0\n",
      "high      0\n",
      "low       0\n",
      "close     0\n",
      "volume    0\n",
      "dtype: int64\n",
      "\n",
      "Original Close Stats:\n",
      "count    158.000000\n",
      "mean     192.321456\n",
      "std       19.455821\n",
      "min      165.000000\n",
      "25%      175.345000\n",
      "50%      187.290000\n",
      "75%      209.785000\n",
      "max      234.820000\n",
      "Name: close, dtype: float64\n",
      "Cleaned Close Stats:\n",
      "count    158.000000\n",
      "mean       0.391313\n",
      "std        0.278657\n",
      "min        0.000000\n",
      "25%        0.148167\n",
      "50%        0.319249\n",
      "75%        0.641435\n",
      "max        1.000000\n",
      "Name: close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare shapes\n",
    "print('Original Data Shape:', df_raw.shape)\n",
    "print('Cleaned Data Shape:', df_clean.shape)\n",
    "\n",
    "# Compare NA counts\n",
    "print('\\nOriginal NA Counts:')\n",
    "print(df_raw.isna().sum())\n",
    "print('Cleaned NA Counts:')\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "# Compare close column statistics\n",
    "print('\\nOriginal Close Stats:')\n",
    "print(df_raw['close'].describe())\n",
    "print('Cleaned Close Stats:')\n",
    "print(df_clean['close'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c7784",
   "metadata": {},
   "source": [
    "## Assumptions and Tradeoffs\n",
    "\n",
    "**Assumptions**:\n",
    "- Missing values in `open`, `high`, `low`, `close`, `volume` are suitable for median imputation due to potential skewness in stock data.\n",
    "- Dropping rows after imputation is safe, as Alpha Vantage data typically has minimal missingness.\n",
    "- Min-Max normalization is appropriate for numeric columns, assuming linear scaling suits downstream models.\n",
    "- The `date` column is non-numeric and only checked for missing values.\n",
    "\n",
    "**Tradeoffs**:\n",
    "- **Median Imputation**: Reduces outlier bias but may oversimplify data distribution compared to mean or interpolation.\n",
    "- **Dropping Rows**: Ensures completeness but risks data loss if missingness is significant.\n",
    "- **Normalization**: Min-Max scaling is simple but sensitive to outliers; standardization (z-score) might be better for some models.\n",
    "- **CSV Output**: Chosen for readability, but Parquet would be more efficient for large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
